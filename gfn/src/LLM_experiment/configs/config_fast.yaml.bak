# LLM Experiment Configuration

# Data paths
trajectory_data_dir: "./data/trajectories_output"
rearc_data_dir: "./data/re-arc"
processed_data_dir: "./processed_data"
model_save_dir: "./models"
results_dir: "./results"

# Training parameters
model_name: "meta-llama/Llama-3.1-8B-Instruct" # Start with smaller model for testing
max_length: 1024
batch_size: 1
learning_rate: 0.00005
num_epochs: 1 # 빠른 테스트를 위해
warmup_steps: 20
gradient_accumulation_steps: 4

# Data preprocessing
max_grid_size: 30
action_mapping:
  0: "left_rotate" # 왼쪽 회전
  1: "right_rotate" # 오른쪽 회전
  2: "horizontal_flip" # 수평 뒤집기
  3: "vertical_flip" # 수직 뒤집기
  4: "submit" # 제출

# Available problem IDs and their ARC task IDs (only available trajectory files)
problem_mapping:
  86: "25ff71a9"
  139: "6150a2bd"
  178: "74dd1130"
  149: "6773b310"
  154: "6855a6e4"
  240: "9d9215db"
  379: "ecdecbb3"

# Evaluation
num_test_samples: 50
max_action_sequence_length: 20

# Environment Configuration
environment:
  python_paths:
    gflownet: "/data/miniforge3/envs/gflownet/bin/python"
    gflow_llm: "/data/miniforge3/envs/gflow-llm/bin/python"
  sys_paths:
    - "/home/ubuntu/GFN_to_ARC/gfn/src"
    - "/home/ubuntu/GFN_to_ARC/gfn/src/ARCenv"
  log_dir: "./logs"

# Training Configuration
training:
  logging_steps: 50
  eval_steps: 500
  save_steps: 500
  eval_strategy: "no"
  dataloader_num_workers: 0
  dataloader_pin_memory: false
  skip_memory_metrics: true
  torch_empty_cache_steps: 5
  ddp_timeout: 7200
  ddp_bucket_cap_mb: 25
  ddp_broadcast_buffers: false
  gradient_checkpointing: false
  random_seed: 3407

# WandB Configuration
wandb:
  project: "arc-action-sequence"
  tags: ["llama3.1", "action_sequence", "arc"]

# Quantization Configuration
quantization:
  load_in_8bit: true
  llm_int8_threshold: 6.0
  llm_int8_has_fp16_weight: false

# Generation Configuration
generation:
  temperature: 0.7
  do_sample: true
  early_stopping: true
  inference_temperature: 0.1

# LoRA Configuration
lora:
  load_in_4bit: true
  r: 16
  lora_alpha: 16
  lora_dropout: 0.05
  bias: "none"
  use_rslora: false
  target_modules: ["q_proj", "k_proj", "v_proj", "o_proj", "gate_proj", "up_proj", "down_proj"]

# Evaluation Configuration
evaluation:
  few_shot_examples: 5
  test_examples_range: [5, 25]
  validation_split_ratio: 0.1

# Optimizer Configuration
optimizer:
  name: "adamw_8bit"
  weight_decay: 0.01
  lr_scheduler_type: "linear"
  dataset_num_proc: 2
  packing: false

# DDP Configuration
ddp:
  backend: "gloo"
  timeout_minutes: 30
