
  0%|                                                                                                                               | 0/1000 [00:00<?, ?it/s]C:\Users\sanha\GFN_to_ARC\gfn\src\gflow\log.py:60: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self._traj.append(torch.tensor(state))
C:\Users\sanha\GFN_to_ARC\gfn\src\gflow\utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  total_flow = torch.tensor(total_flow).to("cuda")




















































7.371:   5%|█████▉                                                                                                       | 54/1000 [08:40<2:31:54,  9.63s/it]
Traceback (most recent call last):
  File "C:\Users\sanha\GFN_to_ARC\gfn\src\main.py", line 109, in <module>
    train(num_epochs, device)
  File "C:\Users\sanha\GFN_to_ARC\gfn\src\main.py", line 56, in train
    result = model.sample_states(state, return_log=True)
  File "C:\Users\sanha\GFN_to_ARC\gfn\src\gflow\gflownet.py", line 70, in sample_states
    self.actions["operation"] = int(Categorical(probs).sample())
  File "C:\Users\sanha\anaconda3\envs\gfn\lib\site-packages\torch\distributions\categorical.py", line 66, in __init__
    super().__init__(batch_shape, validate_args=validate_args)
  File "C:\Users\sanha\anaconda3\envs\gfn\lib\site-packages\torch\distributions\distribution.py", line 62, in __init__
    raise ValueError(
ValueError: Expected parameter probs (Tensor of shape (35,)) of distribution Categorical(probs: torch.Size([35])) to satisfy the constraint Simplex(), but found invalid values:
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
       device='cuda:0', grad_fn=<DivBackward0>)